{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, make_scorer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import Feature_Extraction as fe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = wikipedia.search(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConceptNet5Similarity(term1, term2):\n",
    "    return requests.get('http://api.conceptnet.io/relatedness?node1=/c/en/' + term1 + '&node2=/c/en/' + term2).json()['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConceptNet5: 0.163\n",
      "\n",
      "NLTK WUP: 0.6\n",
      "\n",
      "Average: 0.3815\n",
      "\n",
      "Smart: 0.6\n"
     ]
    }
   ],
   "source": [
    "term1 = 'car' #also check NASA and CIA examples\n",
    "term2 = 'horn'\n",
    "x = getConceptNet5Similarity(term1, term2)\n",
    "y = fe.getWUPSimilarity(term1, term2)\n",
    "if x == None:\n",
    "    x = 0\n",
    "if y == None:\n",
    "    y = 0\n",
    "z = (x+y) / 2\n",
    "t = x\n",
    "if y > x:\n",
    "    t = y\n",
    "#r1 = wikipedia.summary(term1, sentences=1)\n",
    "#r2 = wikipedia.summary(term2, sentences=1)\n",
    "u = fe.getNounSimilarityPortion(r1, r2)\n",
    "print('ConceptNet5: ' + str(x))\n",
    "print()\n",
    "print('NLTK WUP: '+ str(y))\n",
    "print()\n",
    "#print('Wikipedia Summary: '+ str(u))\n",
    "#print()\n",
    "print('Average: ' + str(z))\n",
    "print()\n",
    "print('Smart: ' + str(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='en_core_web_sm'\n",
    "nlp = spacy.load(model)\n",
    "from spacy.lang.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "with open('data/sentences.csv') as f:\n",
    "    for line in f:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.269*\"irrigation\" + 0.085*\"aqualush\" + 0.084*\"setting\" + 0.081*\"allow\"')\n",
      "(1, '0.026*\"current\" + 0.026*\"user\" + 0.026*\"aqualush\" + 0.026*\"allow\"')\n",
      "(2, '0.142*\"aqualush\" + 0.127*\"current\" + 0.096*\"allow\" + 0.096*\"setting\"')\n",
      "(3, '0.303*\"user\" + 0.019*\"current\" + 0.019*\"aqualush\" + 0.019*\"allow\"')\n",
      "(4, '0.150*\"aqualush\" + 0.122*\"setting\" + 0.096*\"display\" + 0.066*\"problem\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga75xoh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el459122341333784520688940178\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el459122341333784520688940178_data = {\"mdsDat\": {\"x\": [-0.1545065991460401, 0.022924050704911936, -0.04749348468278855, 0.03684954180912911, 0.14222649131478743], \"y\": [0.059075215277103174, -0.0325871154554426, -0.001221847736445274, -0.12725781048152543, 0.10199155839631016], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [37.86338424682617, 2.7248051166534424, 37.519508361816406, 3.79709529876709, 18.095199584960938]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [5.0, 17.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 16.0, 10.0, 9.0, 4.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.6875967979431152, 2.6875951290130615, 14.443074226379395, 1.8477449417114258, 1.8477064371109009, 1.0078343152999878, 1.0078341960906982, 1.0078336000442505, 1.00783371925354, 1.0077786445617676, 1.848070740699768, 1.8480703830718994, 1.848068118095398, 4.368448734283447, 1.007297158241272, 4.509771347045898, 4.566910743713379, 1.8418326377868652, 0.16799086332321167, 0.16798777878284454, 0.16798703372478485, 0.1679868996143341, 0.16798418760299683, 0.16798417270183563, 0.16798411309719086, 0.16798406839370728, 0.1679839938879013, 0.1679839938879013, 0.17073982954025269, 0.1699855774641037, 0.16998355090618134, 0.16998256742954254, 0.16998258233070374, 0.16998207569122314, 0.17019541561603546, 0.1680269092321396, 0.10183743387460709, 0.1018185243010521, 0.10181841999292374, 0.10181822627782822, 0.10180442780256271, 0.10180442780256271, 0.10180439054965973, 0.10180439054965973, 0.10180436074733734, 0.10180436819791794, 0.10182256251573563, 0.1018068790435791, 0.10180669277906418, 0.10180669277906418, 0.10180668532848358, 0.10182026773691177, 0.10180509090423584, 0.10180477052927017, 0.10180444270372391, 0.10180440545082092, 0.10180415958166122, 0.10180962830781937, 0.10180329531431198, 0.10185326635837555, 0.10181538760662079, 0.1018054261803627, 0.10182210057973862, 0.10182029753923416, 0.10181985795497894, 0.10183349251747131, 0.1018817201256752, 0.10187806189060211, 0.10186367481946945, 0.10185479372739792, 0.10184353590011597, 0.10184125602245331, 0.101833276450634, 0.10183307528495789, 1.814948320388794, 1.814927101135254, 0.9899500608444214, 0.9899497628211975, 0.989949643611908, 0.9899497628211975, 0.9899493455886841, 0.9899493455886841, 0.9899023175239563, 0.9899014234542847, 0.9899006485939026, 0.9898369312286377, 6.772804260253906, 3.448794364929199, 5.113825798034668, 7.589192867279053, 1.814575433731079, 1.814572811126709, 1.8145720958709717, 0.990365743637085, 5.11292028427124, 2.636898994445801, 0.16500551998615265, 0.1650020182132721, 0.1650020182132721, 0.1650019884109497, 0.16500186920166016, 0.1650083214044571, 0.16500328481197357, 0.16500280797481537, 0.16500285267829895, 0.16500933468341827, 0.16500817239284515, 0.16500674188137054, 0.1650061011314392, 1.6343663930892944, 0.10156572610139847, 0.10155253112316132, 0.10155234485864639, 0.10155222564935684, 0.1015426367521286, 0.10154261440038681, 0.10154251754283905, 0.10154249519109726, 0.10154243558645248, 0.10154237598180771, 0.10155550390481949, 0.10154428333044052, 0.10154422372579575, 0.10154414921998978, 0.10154413431882858, 0.10155490040779114, 0.10154356807470322, 0.10154316574335098, 0.10154283791780472, 0.10154281556606293, 0.10154276341199875, 0.10154630243778229, 0.10154182463884354, 0.10157723724842072, 0.1015511006116867, 0.10154329985380173, 0.10155484080314636, 0.10155370086431503, 0.10155368596315384, 0.10160108655691147, 0.10158815234899521, 0.10158305615186691, 0.10157300531864166, 0.10157158970832825, 0.10156401991844177, 0.10156358778476715, 0.10156264901161194, 2.475783348083496, 1.7016839981079102, 1.7016836404800415, 1.7016820907592773, 1.7016819715499878, 1.7016814947128296, 1.700937032699585, 3.122875928878784, 3.843280076980591, 1.7014423608779907, 0.15488599240779877, 0.1548788994550705, 0.15487892925739288, 0.1548786163330078, 0.15487350523471832, 0.15487349033355713, 0.15487347543239594, 0.15487338602542877, 0.15487335622310638, 0.15487323701381683, 0.15488018095493317, 0.1548747569322586, 0.15487459301948547, 0.15487432479858398, 0.15487432479858398, 0.1548757404088974, 0.15487335622310638, 0.15489248931407928, 0.154878631234169, 0.15487432479858398, 0.16066978871822357, 0.15492747724056244, 0.15489836037158966, 0.1548883020877838, 0.1548863798379898, 0.15488573908805847, 0.15488173067569733, 0.15488138794898987], \"Term\": [\"user\", \"irrigation\", \"display\", \"fail\", \"validation\", \"accept\", \"problem\", \"notify\", \"reset\", \"call\", \"occur\", \"effect\", \"cycle\", \"result\", \"skip\", \"aqualush\", \"current\", \"allow\", \"either\", \"invalid\", \"validate\", \"value\", \"qualush\", \"finish\", \"progress\", \"automatic\", \"completion\", \"consist\", \"closing\", \"different\", \"occur\", \"call\", \"irrigation\", \"cycle\", \"effect\", \"completion\", \"automatic\", \"finish\", \"progress\", \"qualush\", \"invalid\", \"validate\", \"either\", \"allow\", \"value\", \"setting\", \"aqualush\", \"current\", \"consist\", \"different\", \"valve\", \"closing\", \"times\", \"words\", \"attempt\", \"react\", \"detect\", \"make\", \"reset\", \"notify\", \"validation\", \"problem\", \"accept\", \"fail\", \"display\", \"user\", \"consist\", \"different\", \"closing\", \"valve\", \"times\", \"detect\", \"attempt\", \"words\", \"react\", \"make\", \"qualush\", \"finish\", \"progress\", \"automatic\", \"completion\", \"reset\", \"fail\", \"validation\", \"accept\", \"problem\", \"notify\", \"result\", \"skip\", \"value\", \"effect\", \"cycle\", \"display\", \"call\", \"occur\", \"either\", \"current\", \"user\", \"aqualush\", \"allow\", \"setting\", \"irrigation\", \"validate\", \"invalid\", \"skip\", \"result\", \"make\", \"react\", \"detect\", \"words\", \"attempt\", \"times\", \"valve\", \"closing\", \"different\", \"consist\", \"current\", \"user\", \"allow\", \"aqualush\", \"validate\", \"invalid\", \"either\", \"value\", \"setting\", \"irrigation\", \"qualush\", \"finish\", \"completion\", \"automatic\", \"progress\", \"reset\", \"accept\", \"fail\", \"problem\", \"display\", \"call\", \"occur\", \"effect\", \"user\", \"consist\", \"closing\", \"different\", \"valve\", \"attempt\", \"react\", \"detect\", \"times\", \"words\", \"make\", \"qualush\", \"progress\", \"automatic\", \"finish\", \"completion\", \"reset\", \"fail\", \"validation\", \"notify\", \"accept\", \"problem\", \"result\", \"skip\", \"value\", \"effect\", \"cycle\", \"display\", \"call\", \"occur\", \"current\", \"aqualush\", \"allow\", \"setting\", \"irrigation\", \"either\", \"invalid\", \"validate\", \"display\", \"problem\", \"accept\", \"fail\", \"validation\", \"notify\", \"reset\", \"setting\", \"aqualush\", \"current\", \"consist\", \"closing\", \"different\", \"valve\", \"times\", \"attempt\", \"detect\", \"make\", \"words\", \"react\", \"qualush\", \"progress\", \"finish\", \"completion\", \"automatic\", \"result\", \"skip\", \"value\", \"effect\", \"cycle\", \"irrigation\", \"user\", \"allow\", \"either\", \"invalid\", \"validate\", \"occur\", \"call\"], \"Total\": [5.0, 17.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 16.0, 10.0, 9.0, 4.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.2108585834503174, 3.2108585834503174, 17.444055557250977, 2.3709700107574463, 2.370957612991333, 1.5310614109039307, 1.5310614109039307, 1.5310611724853516, 1.5310612916946411, 1.531042456626892, 4.0209269523620605, 4.020927429199219, 4.020925998687744, 9.840611457824707, 2.3559858798980713, 12.948984146118164, 16.202835083007812, 10.519561767578125, 1.516116976737976, 1.5161383152008057, 1.5161384344100952, 1.5161380767822266, 1.5161539316177368, 1.516154170036316, 1.5161539316177368, 1.5161540508270264, 1.5161540508270264, 1.516154170036316, 2.240060329437256, 2.2400166988372803, 2.240016222000122, 2.240016460418701, 2.2400166988372803, 2.2400155067443848, 3.0143651962280273, 5.507993221282959, 1.516116976737976, 1.5161383152008057, 1.5161380767822266, 1.5161384344100952, 1.5161539316177368, 1.5161540508270264, 1.5161539316177368, 1.516154170036316, 1.5161540508270264, 1.516154170036316, 1.531042456626892, 1.5310611724853516, 1.5310612916946411, 1.5310614109039307, 1.5310614109039307, 2.240060329437256, 2.2400155067443848, 2.240016222000122, 2.2400166988372803, 2.240016460418701, 2.2400166988372803, 2.341144323348999, 2.341151237487793, 2.3559858798980713, 2.370957612991333, 2.3709700107574463, 3.0143651962280273, 3.2108585834503174, 3.2108585834503174, 4.020925998687744, 10.519561767578125, 5.507993221282959, 16.202835083007812, 9.840611457824707, 12.948984146118164, 17.444055557250977, 4.020927429199219, 4.0209269523620605, 2.341151237487793, 2.341144323348999, 1.516154170036316, 1.5161540508270264, 1.5161540508270264, 1.516154170036316, 1.5161539316177368, 1.5161539316177368, 1.5161384344100952, 1.5161380767822266, 1.5161383152008057, 1.516116976737976, 10.519561767578125, 5.507993221282959, 9.840611457824707, 16.202835083007812, 4.020927429199219, 4.0209269523620605, 4.020925998687744, 2.3559858798980713, 12.948984146118164, 17.444055557250977, 1.531042456626892, 1.5310611724853516, 1.5310614109039307, 1.5310614109039307, 1.5310612916946411, 2.240060329437256, 2.2400166988372803, 2.2400155067443848, 2.240016460418701, 3.0143651962280273, 3.2108585834503174, 3.2108585834503174, 2.370957612991333, 5.507993221282959, 1.516116976737976, 1.5161380767822266, 1.5161383152008057, 1.5161384344100952, 1.5161539316177368, 1.5161540508270264, 1.5161540508270264, 1.5161539316177368, 1.516154170036316, 1.516154170036316, 1.531042456626892, 1.5310612916946411, 1.5310614109039307, 1.5310611724853516, 1.5310614109039307, 2.240060329437256, 2.2400155067443848, 2.240016222000122, 2.2400166988372803, 2.2400166988372803, 2.240016460418701, 2.341144323348999, 2.341151237487793, 2.3559858798980713, 2.370957612991333, 2.3709700107574463, 3.0143651962280273, 3.2108585834503174, 3.2108585834503174, 10.519561767578125, 16.202835083007812, 9.840611457824707, 12.948984146118164, 17.444055557250977, 4.020925998687744, 4.0209269523620605, 4.020927429199219, 3.0143651962280273, 2.240016460418701, 2.2400166988372803, 2.2400155067443848, 2.240016222000122, 2.2400166988372803, 2.240060329437256, 12.948984146118164, 16.202835083007812, 10.519561767578125, 1.516116976737976, 1.5161380767822266, 1.5161383152008057, 1.5161384344100952, 1.5161539316177368, 1.5161539316177368, 1.5161540508270264, 1.516154170036316, 1.516154170036316, 1.5161540508270264, 1.531042456626892, 1.5310612916946411, 1.5310611724853516, 1.5310614109039307, 1.5310614109039307, 2.341144323348999, 2.341151237487793, 2.3559858798980713, 2.370957612991333, 2.3709700107574463, 17.444055557250977, 5.507993221282959, 9.840611457824707, 4.020925998687744, 4.0209269523620605, 4.020927429199219, 3.2108585834503174, 3.2108585834503174], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7932999730110168, 0.7932999730110168, 0.7824000120162964, 0.7218999862670898, 0.7218000292778015, 0.5529999732971191, 0.5529999732971191, 0.5529999732971191, 0.5529999732971191, 0.5529999732971191, 0.19380000233650208, 0.19380000233650208, 0.19380000233650208, 0.1590999960899353, 0.12150000035762787, -0.0835999995470047, -0.295199990272522, -0.7713000178337097, -1.2288000583648682, -1.2288000583648682, -1.2288000583648682, -1.2288999557495117, -1.2288999557495117, -1.2288999557495117, -1.2288999557495117, -1.2288999557495117, -1.2288999557495117, -1.2288999557495117, -1.6029000282287598, -1.607300043106079, -1.6073999404907227, -1.6073999404907227, -1.6073999404907227, -1.6073999404907227, -1.902999997138977, -2.5185999870300293, 0.9021999835968018, 0.9020000100135803, 0.9020000100135803, 0.9020000100135803, 0.9018999934196472, 0.9018999934196472, 0.9018999934196472, 0.9018999934196472, 0.9018999934196472, 0.9018999934196472, 0.892300009727478, 0.8920999765396118, 0.8920999765396118, 0.8920999765396118, 0.8920999765396118, 0.5116999745368958, 0.5116000175476074, 0.5116000175476074, 0.5116000175476074, 0.5116000175476074, 0.5116000175476074, 0.4675000011920929, 0.4674000144004822, 0.46160000562667847, 0.45489999651908875, 0.454800009727478, 0.21490000188350677, 0.1517000049352646, 0.1517000049352646, -0.07320000231266022, -1.0343999862670898, -0.3874000012874603, -1.4665000438690186, -0.9679999947547913, -1.2425999641418457, -1.5405999422073364, -0.07320000231266022, -0.07320000231266022, 0.7257000207901001, 0.7257000207901001, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5540000200271606, 0.5539000034332275, 0.5400000214576721, 0.5120999813079834, 0.3257000148296356, 0.22179999947547913, 0.18459999561309814, 0.18459999561309814, 0.18459999561309814, 0.1137000024318695, 0.051100000739097595, -0.9090999960899353, -1.2474000453948975, -1.2474000453948975, -1.2474000453948975, -1.2474000453948975, -1.247499942779541, -1.628000020980835, -1.628000020980835, -1.628000020980835, -1.628000020980835, -1.9248000383377075, -1.9880000352859497, -1.9880000352859497, -1.6848000288009644, 2.055999994277954, 0.5677000284194946, 0.5676000118255615, 0.5676000118255615, 0.5676000118255615, 0.5674999952316284, 0.5674999952316284, 0.5674999952316284, 0.5674999952316284, 0.5674999952316284, 0.5674999952316284, 0.5577999949455261, 0.557699978351593, 0.557699978351593, 0.557699978351593, 0.557699978351593, 0.17730000615119934, 0.17720000445842743, 0.17720000445842743, 0.17720000445842743, 0.17720000445842743, 0.17720000445842743, 0.1331000030040741, 0.13300000131130219, 0.12700000405311584, 0.12039999663829803, 0.12039999663829803, -0.11959999799728394, -0.18279999494552612, -0.18279999494552612, -1.36899995803833, -1.8011000156402588, -1.3025000095367432, -1.5771000385284424, -1.875100016593933, -0.4075999855995178, -0.4075999855995178, -0.4077000021934509, 1.5126999616622925, 1.4347000122070312, 1.4347000122070312, 1.4347000122070312, 1.4347000122070312, 1.4347000122070312, 1.4342000484466553, 0.2872999906539917, 0.27070000767707825, -0.11219999939203262, -0.5716999769210815, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5717999935150146, -0.5814999938011169, -0.58160001039505, -0.58160001039505, -0.58160001039505, -0.58160001039505, -1.0061999559402466, -1.0062999725341797, -1.0125000476837158, -1.0189000368118286, -1.0189000368118286, -2.9779000282287598, -1.8615000247955322, -2.441999912261963, -1.5470000505447388, -1.5470999479293823, -1.5470999479293823, -1.322100043296814, -1.322100043296814], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.996000051498413, -2.996000051498413, -1.3143999576568604, -3.370699882507324, -3.370699882507324, -3.976799964904785, -3.976799964904785, -3.976799964904785, -3.976799964904785, -3.976900100708008, -3.370500087738037, -3.370500087738037, -3.370500087738037, -2.510200023651123, -3.977400064468384, -2.4783999919891357, -2.4658000469207764, -3.3738999366760254, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.768499851226807, -5.752299785614014, -5.756700038909912, -5.756700038909912, -5.756700038909912, -5.756700038909912, -5.756700038909912, -5.75540018081665, -5.7683000564575195, -3.637399911880493, -3.6375999450683594, -3.6375999450683594, -3.6375999450683594, -3.6377999782562256, -3.6377999782562256, -3.6377999782562256, -3.6377999782562256, -3.6377999782562256, -3.6377999782562256, -3.6375999450683594, -3.637700080871582, -3.637700080871582, -3.637700080871582, -3.637700080871582, -3.6375999450683594, -3.637700080871582, -3.6377999782562256, -3.6377999782562256, -3.6377999782562256, -3.6377999782562256, -3.637700080871582, -3.6377999782562256, -3.6373000144958496, -3.6375999450683594, -3.637700080871582, -3.6375999450683594, -3.6375999450683594, -3.6375999450683594, -3.637500047683716, -3.63700008392334, -3.63700008392334, -3.637200117111206, -3.6373000144958496, -3.637399911880493, -3.637399911880493, -3.637500047683716, -3.637500047683716, -3.379499912261963, -3.379499912261963, -3.985599994659424, -3.985599994659424, -3.985599994659424, -3.985599994659424, -3.985599994659424, -3.985599994659424, -3.9856998920440674, -3.9856998920440674, -3.9856998920440674, -3.9856998920440674, -2.0625998973846436, -2.737499952316284, -2.343600034713745, -1.948799967765808, -3.379699945449829, -3.379699945449829, -3.379699945449829, -3.9851999282836914, -2.3436999320983887, -3.0058999061584473, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -5.777299880981445, -1.193600058555603, -3.97189998626709, -3.972100019454956, -3.972100019454956, -3.972100019454956, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9719998836517334, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9719998836517334, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.9721999168395996, -3.972100019454956, -3.9721999168395996, -3.9718000888824463, -3.972100019454956, -3.9721999168395996, -3.9719998836517334, -3.972100019454956, -3.972100019454956, -3.97160005569458, -3.9716999530792236, -3.9718000888824463, -3.97189998626709, -3.97189998626709, -3.9719998836517334, -3.9719998836517334, -3.9719998836517334, -2.3396999835968018, -2.7146999835968018, -2.7146999835968018, -2.7146999835968018, -2.7146999835968018, -2.7146999835968018, -2.715100049972534, -2.1075000762939453, -1.899999976158142, -2.7147998809814453, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111499786376953, -5.111499786376953, -5.111499786376953, -5.111499786376953, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111499786376953, -5.111299991607666, -5.111400127410889, -5.111400127410889, -5.074699878692627, -5.111100196838379, -5.111299991607666, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889, -5.111400127410889]}, \"token.table\": {\"Topic\": [5, 1, 3, 1, 3, 5, 3, 1, 1, 3, 1, 3, 1, 3, 5, 1, 3, 3, 5, 1, 1, 3, 5, 1, 1, 3, 1, 3, 3, 5, 1, 5, 1, 1, 3, 5, 3, 1, 3, 5, 3, 3, 3, 4, 1, 3, 5, 1, 3, 3, 3], \"Freq\": [0.8928504586219788, 0.40647879242897034, 0.5080984830856323, 0.3085879683494568, 0.4937407672405243, 0.24687038362026215, 0.6595636606216431, 0.6531416773796082, 0.9343295097351074, 0.6595705151557922, 0.6531416773796082, 0.6595796942710876, 0.19012199342250824, 0.6654269695281982, 0.19012199342250824, 0.8435366153717041, 0.6595636010169983, 0.6595704555511475, 0.6634896397590637, 0.8435410261154175, 0.49739786982536316, 0.49739786982536316, 0.892850935459137, 0.6531417965888977, 0.4973977506160736, 0.4973977506160736, 0.8025656342506409, 0.17197835445404053, 0.6595635414123535, 0.8928504586219788, 0.9343295097351074, 0.8928505778312683, 0.6531417369842529, 0.6531497240066528, 0.6595636010169983, 0.8928331136703491, 0.8542830944061279, 0.386130690574646, 0.386130690574646, 0.23167841136455536, 0.8542805910110474, 0.6595636606216431, 0.5446629524230957, 0.36310866475105286, 0.49739769101142883, 0.49739769101142883, 0.8928506970405579, 0.42445075511932373, 0.42445075511932373, 0.6595703959465027, 0.6595635414123535], \"Term\": [\"accept\", \"allow\", \"allow\", \"aqualush\", \"aqualush\", \"aqualush\", \"attempt\", \"automatic\", \"call\", \"closing\", \"completion\", \"consist\", \"current\", \"current\", \"current\", \"cycle\", \"detect\", \"different\", \"display\", \"effect\", \"either\", \"either\", \"fail\", \"finish\", \"invalid\", \"invalid\", \"irrigation\", \"irrigation\", \"make\", \"notify\", \"occur\", \"problem\", \"progress\", \"qualush\", \"react\", \"reset\", \"result\", \"setting\", \"setting\", \"setting\", \"skip\", \"times\", \"user\", \"user\", \"validate\", \"validate\", \"validation\", \"value\", \"value\", \"valve\", \"words\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el459122341333784520688940178\", ldavis_el459122341333784520688940178_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el459122341333784520688940178\", ldavis_el459122341333784520688940178_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el459122341333784520688940178\", ldavis_el459122341333784520688940178_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model5.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2eecd4c1ac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [235,24,5,6,300,350,90,16,250,133,5]\n",
    "sns.swarmplot(x=X, size=10, color=\".1\", orient=\"v\")\n",
    "sns.boxplot(x=X, whis=np.inf, orient=\"v\", showmeans=True, palette=\"pastel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "data = open('data/tousend_cons_rels.CSV', encoding=\"ANSI\").read()\n",
    "label, r1, r2, rmix = [], [], [], []\n",
    "size = 500\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    if i >= size:\n",
    "        break\n",
    "    if line != '' and line.isspace() != True:\n",
    "        content = line.split(';')\n",
    "        label.append(content[0])\n",
    "        r1.append(content[1])\n",
    "        r2.append(content[2])\n",
    "        rmix.append(content[1]+content[2])\n",
    "        \n",
    "index = 0\n",
    "size = len(label)\n",
    "x = []\n",
    "while index < size:\n",
    "    x.append(fe.createFBag(r1[index], r2[index]))\n",
    "    index = index + 1\n",
    "    \n",
    "vec = DictVectorizer()\n",
    "\n",
    "xx = vec.fit_transform(x).toarray()\n",
    "\n",
    "yy = []\n",
    "for l in label:\n",
    "    if l == 'true':\n",
    "        yy.append(1)\n",
    "    else:\n",
    "        yy.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isStopWord(w):\n",
    "    if w in set(nltk.corpus.stopwords.words('english')):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "def calculateCosine(s1, s2):\n",
    "    sw = stopwords.words('english')  \n",
    "    s1_list = word_tokenize(s1)  \n",
    "    s2_list = word_tokenize(s2)\n",
    "    # remove stop words from string \n",
    "    s1_set = {w for w in s1_list if not w in sw}  \n",
    "    s2_set = {w for w in s2_list if not w in sw}\n",
    "    l1 =[]\n",
    "    l2 =[] \n",
    "    # form a set containing keywords of both strings  \n",
    "    rvector = s1_set.union(s2_set)  \n",
    "    for w in rvector: \n",
    "        if w in s1_set:\n",
    "            l1.append(1)\n",
    "        else:\n",
    "            l1.append(0) \n",
    "        if w in s2_set:\n",
    "            l2.append(1) \n",
    "        else:\n",
    "            l2.append(0)\n",
    "    c = 0\n",
    "    # cosine formula\n",
    "    for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i]\n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyCosine(s1, s2, threshold):\n",
    "    cos = calculateCosine(s1, s2)\n",
    "    if cos > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def classifyAllCosine(threshold):\n",
    "    predicted = []\n",
    "    for i in range(len(yy)):\n",
    "        predicted.append(classifyCosine(r1[i], r2[i], threshold))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.03      0.06       449\n",
      "           1       0.10      1.00      0.19        51\n",
      "\n",
      "    accuracy                           0.13       500\n",
      "   macro avg       0.55      0.52      0.13       500\n",
      "weighted avg       0.91      0.13      0.07       500\n",
      "\n",
      "--------------------\n",
      "0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.03      0.06       449\n",
      "           1       0.10      1.00      0.19        51\n",
      "\n",
      "    accuracy                           0.13       500\n",
      "   macro avg       0.55      0.52      0.13       500\n",
      "weighted avg       0.91      0.13      0.07       500\n",
      "\n",
      "--------------------\n",
      "0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.09      0.17       449\n",
      "           1       0.10      0.92      0.19        51\n",
      "\n",
      "    accuracy                           0.18       500\n",
      "   macro avg       0.51      0.51      0.18       500\n",
      "weighted avg       0.83      0.18      0.17       500\n",
      "\n",
      "--------------------\n",
      "0.15000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.16      0.28       449\n",
      "           1       0.11      0.88      0.19        51\n",
      "\n",
      "    accuracy                           0.24       500\n",
      "   macro avg       0.52      0.52      0.23       500\n",
      "weighted avg       0.84      0.24      0.27       500\n",
      "\n",
      "--------------------\n",
      "0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.22      0.36       449\n",
      "           1       0.10      0.78      0.18        51\n",
      "\n",
      "    accuracy                           0.28       500\n",
      "   macro avg       0.50      0.50      0.27       500\n",
      "weighted avg       0.82      0.28      0.34       500\n",
      "\n",
      "--------------------\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.37      0.53       449\n",
      "           1       0.10      0.65      0.18        51\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.50      0.51      0.35       500\n",
      "weighted avg       0.82      0.40      0.49       500\n",
      "\n",
      "--------------------\n",
      "0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.51      0.65       449\n",
      "           1       0.12      0.57      0.19        51\n",
      "\n",
      "    accuracy                           0.51       500\n",
      "   macro avg       0.51      0.54      0.42       500\n",
      "weighted avg       0.83      0.51      0.61       500\n",
      "\n",
      "--------------------\n",
      "0.35000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.65      0.76       449\n",
      "           1       0.14      0.51      0.22        51\n",
      "\n",
      "    accuracy                           0.63       500\n",
      "   macro avg       0.53      0.58      0.49       500\n",
      "weighted avg       0.84      0.63      0.70       500\n",
      "\n",
      "--------------------\n",
      "0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.76      0.84       449\n",
      "           1       0.18      0.45      0.25        51\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.55      0.61      0.54       500\n",
      "weighted avg       0.85      0.73      0.78       500\n",
      "\n",
      "--------------------\n",
      "0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.85      0.88       449\n",
      "           1       0.18      0.29      0.22        51\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.55      0.57      0.55       500\n",
      "weighted avg       0.84      0.79      0.81       500\n",
      "\n",
      "--------------------\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.88      0.89       449\n",
      "           1       0.15      0.18      0.16        51\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.53      0.53      0.53       500\n",
      "weighted avg       0.83      0.81      0.82       500\n",
      "\n",
      "--------------------\n",
      "0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.93      0.91       449\n",
      "           1       0.15      0.12      0.13        51\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.53      0.52      0.52       500\n",
      "weighted avg       0.83      0.84      0.83       500\n",
      "\n",
      "--------------------\n",
      "0.6000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.94      0.92       449\n",
      "           1       0.04      0.02      0.03        51\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.47      0.48      0.47       500\n",
      "weighted avg       0.81      0.85      0.83       500\n",
      "\n",
      "--------------------\n",
      "0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.96      0.92       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.86       500\n",
      "   macro avg       0.45      0.48      0.46       500\n",
      "weighted avg       0.80      0.86      0.83       500\n",
      "\n",
      "--------------------\n",
      "0.7000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.97      0.93       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.87       500\n",
      "   macro avg       0.45      0.49      0.47       500\n",
      "weighted avg       0.80      0.87      0.84       500\n",
      "\n",
      "--------------------\n",
      "0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.98      0.94       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.45      0.49      0.47       500\n",
      "weighted avg       0.80      0.88      0.84       500\n",
      "\n",
      "--------------------\n",
      "0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.99      0.94       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.45      0.49      0.47       500\n",
      "weighted avg       0.81      0.89      0.84       500\n",
      "\n",
      "--------------------\n",
      "0.8500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.99      0.94       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.45      0.49      0.47       500\n",
      "weighted avg       0.81      0.89      0.84       500\n",
      "\n",
      "--------------------\n",
      "0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.99      0.94       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.45      0.49      0.47       500\n",
      "weighted avg       0.81      0.89      0.84       500\n",
      "\n",
      "--------------------\n",
      "0.9500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.99      0.94       449\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.45      0.49      0.47       500\n",
      "weighted avg       0.81      0.89      0.84       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,1,0.05):\n",
    "    predicted = classifyAllCosine(i)\n",
    "    print('--------------------')\n",
    "    print(i)\n",
    "    print(classification_report(yy, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyOnSimilarity(s1, s2):\n",
    "    threshold = 0.3\n",
    "    ns = fe.getNounSimilarityPortion(s1, s2)\n",
    "    if ns == 'low':\n",
    "        ns = 0\n",
    "    vs = fe.getVerbSimilarityPortion(s1, s2)\n",
    "    if vs == 'low':\n",
    "        vs = 0\n",
    "    sim = (ns + vs) / 2\n",
    "    myy = -1\n",
    "    if sim > threshold:\n",
    "        myy = 1\n",
    "    return myy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
