{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from joblib import dump, load\n",
    "import json\n",
    "\n",
    "import Feature_Extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "data = open('data/with_ppu.CSV', encoding=\"ANSI\").read()\n",
    "label, r1, r2, rmix = [], [], [], []\n",
    "size = 500\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    if i >= size:\n",
    "        break\n",
    "    if line != '' and line.isspace() != True:\n",
    "        content = line.split(';')\n",
    "        label.append(content[0])\n",
    "        r1.append(content[1])\n",
    "        r2.append(content[2])\n",
    "        rmix.append(content[1]+content[2])\n",
    "        \n",
    "index = 0\n",
    "size = len(label)\n",
    "x = []\n",
    "while index < size:\n",
    "    x.append(fe.createFBag(r1[index], r2[index]))\n",
    "    index = index + 1\n",
    "    \n",
    "\n",
    "yy = []\n",
    "for l in label:\n",
    "    if l == 'true':\n",
    "        yy.append(1)\n",
    "    else:\n",
    "        yy.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_clf = ExtraTreesClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "\n",
    "vec.fit(x)\n",
    "xx = vec.transform(x).toarray()\n",
    "dump(vec, \"vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extra_tree.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET_clf.fit(xx, yy)\n",
    "dump(ET_clf, \"extra_tree.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = \"PPU should have sensors to read current power consumption.\"\n",
    "r2 = \"The time to handle, stamp and sort all of the work pieces should be 5 minutes.\"\n",
    "r3 = \"An emergency stop button must be integrated with PPU to halt the operations safely without causing any damage to the system in case of emergency.\"\n",
    "x = fe.createFBag(r2, r3)\n",
    "ET_clf.predict(vec.transform(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
