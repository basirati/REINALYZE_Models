{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model='en_core_web_sm'\n",
    "nlp = spacy.load(model)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrigDep(word):\n",
    "    if (word.dep_ != 'conj'):\n",
    "        return word.dep_\n",
    "    return getOrigDep(word.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSynAnt(word):\n",
    "    synonyms = [] \n",
    "    antonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "            if l.antonyms(): \n",
    "                antonyms.append(l.antonyms()[0].name()) \n",
    "    return synonyms, antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWUPSimilarity(w1, w2):\n",
    "    doc1 = nlp(w1)\n",
    "    doc2 = nlp(w2)\n",
    "    if doc1[0].lemma_ == doc2[0].lemma_:\n",
    "        return 1\n",
    "    synonyms, _ = getSynAnt(w1)\n",
    "    if w2 in synonyms:\n",
    "        return 0.9\n",
    "    synonyms, _ = getSynAnt(w2)\n",
    "    if w1 in synonyms:\n",
    "        return 0.9\n",
    "\n",
    "    #NOUN\n",
    "    synw1s = wordnet.synsets(w1, wordnet.NOUN)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "    #VERB\n",
    "    synw1s = wordnet.synsets(w1, wordnet.VERB)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "    #ADJ\n",
    "    synw1s = wordnet.synsets(w1, wordnet.ADJ)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "    #ADV\n",
    "    synw1s = wordnet.synsets(w1, wordnet.ADV)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAntonymity(w1, w2): \n",
    "    antonyms = [] \n",
    "    for syn in wordnet.synsets(w1): \n",
    "        for l in syn.lemmas(): \n",
    "            if l.antonyms():\n",
    "                antonyms.append(l.antonyms()[0].name()) \n",
    "    if len(antonyms) < 1:\n",
    "        return 0\n",
    "    if w2 in antonyms:\n",
    "        return 1\n",
    "    avg = 0\n",
    "    for a in antonyms:\n",
    "        tmp = getWUPSimilarity(w2, a)\n",
    "        if tmp == None:\n",
    "            tmp = 0\n",
    "        avg = avg + tmp\n",
    "    if len(antonyms) > 0:\n",
    "        avg = avg / len(antonyms)\n",
    "    else:\n",
    "        return 0\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSimAnt(sim):\n",
    "    if sim == None:\n",
    "        sim = 'nothing'\n",
    "    elif sim < 0.2:\n",
    "        sim = 'low'\n",
    "    elif 0.2 <= sim < 0.4:\n",
    "        sim = 'some'\n",
    "    elif 0.4 <= sim < 0.6:\n",
    "        sim = 'medium'\n",
    "    elif 0.6 <= sim < 0.8:\n",
    "        sim = 'much'\n",
    "    elif 0.8 <= sim < 0.95:\n",
    "        sim = 'high'\n",
    "    elif 0.95 <= sim:\n",
    "        sim = 'strong'\n",
    "        \n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStcSubObjFeatures(s1, s2):\n",
    "    doc1 = nlp(s1)\n",
    "    doc2 = nlp(s2)\n",
    "    sfts = {'subjsubj' : 0, 'subjsubjn': 0, 'subjobj' : 0, 'subjobjn' : 0, 'objsubj' : 0, 'objsubjn' : 0, 'objobj' : 0, 'objobjn' : 0}\n",
    "    afts = {'asubjsubj' : 0, 'asubjsubjn': 0, 'asubjobj' : 0, 'asubjobjn' : 0, 'aobjsubj' : 0, 'aobjsubjn' : 0, 'aobjobj' : 0, 'aobjobjn' : 0}\n",
    "    state = 'none'\n",
    "    for t1 in doc1:\n",
    "        if getOrigDep(t1).endswith('subj'):\n",
    "            state = 'subj'\n",
    "        elif getOrigDep(t1).endswith('obj'):\n",
    "            state = 'obj'\n",
    "        else:\n",
    "            continue\n",
    "        state2 = 'none'\n",
    "        for t2 in doc2:\n",
    "            if getOrigDep(t2).endswith('subj'):\n",
    "                state2 = 'subj'\n",
    "            elif getOrigDep(t2).endswith('obj'):\n",
    "                state2 = 'obj'\n",
    "            else:\n",
    "                continue\n",
    "            #similarity = normalizeSimAnt(getWUPSimilarity(t1.text, t2.text))\n",
    "            #antonymity = normalizeSimAnt(getAntonymity(t1.text, t2.text))\n",
    "            #if similarity != 'nothing' and similarity != 'low':\n",
    "            #    features.append('SIMILAR_' + state + state2 + '_' + similarity)\n",
    "            #if antonymity != 'nothing' and antonymity != 'low':\n",
    "            #    features.append('ANTONYM_' + state + state2 + '_' + antonymity)\n",
    "            similarity = getWUPSimilarity(t1.text, t2.text)\n",
    "            if similarity == None:\n",
    "                similarity = 0\n",
    "            antonymity = getAntonymity(t1.text, t2.text)\n",
    "            sfts[state+state2] = sfts[state+state2] + similarity\n",
    "            sfts[state+state2+'n'] = sfts[state+state2+'n'] + 1\n",
    "            afts['a'+state+state2] = afts['a'+state+state2] + antonymity\n",
    "            afts['a'+state+state2+'n'] = afts['a'+state+state2+'n'] + 1\n",
    "    \n",
    "    if sfts['subjsubj' + 'n'] > 0:\n",
    "        sfts['subjsubj'] = normalizeSimAnt(sfts['subjsubj'] / sfts['subjsubj' + 'n'])\n",
    "    if sfts['subjobj' + 'n'] > 0:\n",
    "        sfts['subjobj'] = normalizeSimAnt(sfts['subjobj'] / sfts['subjobj' + 'n'])\n",
    "    if sfts['objsubj' + 'n']  > 0:\n",
    "        sfts['objsubj'] = normalizeSimAnt(sfts['objsubj'] / sfts['objsubj' + 'n'])\n",
    "    if sfts['objobj' + 'n'] > 0:\n",
    "        sfts['objobj'] = normalizeSimAnt(sfts['objobj'] / sfts['objobj' + 'n'])\n",
    "    \n",
    "    if afts['asubjsubj' + 'n'] > 0:\n",
    "        afts['asubjsubj'] = normalizeSimAnt(afts['asubjsubj'] / afts['asubjsubj' + 'n'])\n",
    "    if afts['asubjobj' + 'n'] > 0:\n",
    "        afts['asubjobj'] = normalizeSimAnt(afts['asubjobj'] / afts['asubjobj' + 'n'])\n",
    "    if afts['aobjsubj' + 'n'] > 0:\n",
    "        afts['aobjsubj'] = normalizeSimAnt(afts['aobjsubj'] / afts['aobjsubj' + 'n'])\n",
    "    if afts['aobjobj' + 'n'] > 0:\n",
    "        afts['aobjobj'] = normalizeSimAnt(afts['aobjobj'] / afts['aobjobj' + 'n'])\n",
    "    \n",
    "    sfts.update(afts)\n",
    "    return sfts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSimAnt2(sim):\n",
    "    if sim == None:\n",
    "        sim = 0\n",
    "    elif sim < 0.2:\n",
    "        sim = 0\n",
    "    elif 0.2 <= sim < 0.8:\n",
    "        sim = 0.5\n",
    "    elif 0.8 <= sim:\n",
    "        sim = 1\n",
    "        \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStcSubObjFeatures2(s1, s2):\n",
    "    doc1 = nlp(s1)\n",
    "    doc2 = nlp(s2)\n",
    "    sfts = {'subjsubj' : 0, 'subjobj' : 0, 'objsubj' : 0, 'objobj' : 0}\n",
    "    afts = {'asubjsubj' : 0, 'asubjobj' : 0, 'aobjsubj' : 0, 'aobjobj' : 0}\n",
    "    state = 'none'\n",
    "    for t1 in doc1:\n",
    "        if getOrigDep(t1).endswith('subj'):\n",
    "            state = 'subj'\n",
    "        elif getOrigDep(t1).endswith('obj'):\n",
    "            state = 'obj'\n",
    "        else:\n",
    "            continue\n",
    "        state2 = 'none'\n",
    "        for t2 in doc2:\n",
    "            if getOrigDep(t2).endswith('subj'):\n",
    "                state2 = 'subj'\n",
    "            elif getOrigDep(t2).endswith('obj'):\n",
    "                state2 = 'obj'\n",
    "            else:\n",
    "                continue\n",
    "          \n",
    "            similarity = normalizeSimAnt2(getWUPSimilarity(t1.text, t2.text))\n",
    "            antonymity = normalizeSimAnt2(getAntonymity(t1.text, t2.text))\n",
    "            if similarity > 0:\n",
    "                if sfts[state+state2] < similarity:\n",
    "                    sfts[state+state2] = similarity\n",
    "            if antonymity > 0:\n",
    "                    if afts['a'+state+state2] < antonymity:\n",
    "                        afts['a'+state+state2] = antonymity\n",
    "    \n",
    "    sfts.update(afts)\n",
    "    return sfts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def isStopWord(w):\n",
    "    if w.pos_ == 'DET':\n",
    "        return True\n",
    "    if w in set(nltk.corpus.stopwords.words('english')):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounLemmas(s):\n",
    "    res = []\n",
    "    doc = nlp(s)\n",
    "    for nc in doc.noun_chunks:\n",
    "        for t in nc:\n",
    "            if not(isStopWord(t)):\n",
    "                res.append(t.lemma_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounSimilarityPortion(r1, r2):\n",
    "    ns1 = getNounLemmas(r1)\n",
    "    ns2 = getNounLemmas(r2)\n",
    "    if len(ns1) < 1 or len(ns2) < 1:\n",
    "        return 'low'\n",
    "    num1 = 0\n",
    "    for n in ns1:\n",
    "        for m in ns2:\n",
    "            if n == m:\n",
    "                num1 = num1 + 1\n",
    "                break\n",
    "    if len(ns1) > 0:\n",
    "        ovlap = num1/len(ns1)\n",
    "    else:\n",
    "        ovlap = 0\n",
    "    if ovlap < 0.2:\n",
    "        ovlap = 0\n",
    "    elif 0.2 <= ovlap < 0.4:\n",
    "        ovlap = 0.3\n",
    "    elif 0.4 <= ovlap < 0.6:\n",
    "        ovlap = 0.5\n",
    "    elif 0.6 <= ovlap < 0.8:\n",
    "        ovlap = 0.7\n",
    "    elif 0.8 <= ovlap:\n",
    "        ovlap = 1\n",
    "    return ovlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNSPFeatures(r1, r2):\n",
    "    res = {'noun_ovlap_1_2' : getNounSimilarityPortion(r1, r2), 'noun_ovlap_2_1' : getNounSimilarityPortion(r2, r1)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVerbLemmas(s):\n",
    "    res = []\n",
    "    doc = nlp(s)\n",
    "    for t in doc:\n",
    "        if t.tag_.startswith('VB'):\n",
    "            res.append(t.lemma_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVerbSimilarityPortion(r1, r2):\n",
    "    vs1 = getVerbLemmas(r1)\n",
    "    vs2 = getVerbLemmas(r2)\n",
    "    if len(vs1) < 1 or len(vs2) < 1:\n",
    "        return 'low'\n",
    "    num1 = 0\n",
    "    for n in vs1:\n",
    "        for m in vs2:\n",
    "            if n == m:\n",
    "                num1 = num1 + 1\n",
    "                break\n",
    "    if len(vs1) > 0:\n",
    "        ovlap = num1/len(vs1)\n",
    "    else:\n",
    "        ovlap = 0\n",
    "    if ovlap < 0.2:\n",
    "        ovlap = 0\n",
    "    elif 0.2 <= ovlap < 0.4:\n",
    "        ovlap = 0.3\n",
    "    elif 0.4 <= ovlap < 0.6:\n",
    "        ovlap = 0.5\n",
    "    elif 0.6 <= ovlap < 0.8:\n",
    "        ovlap = 0.7\n",
    "    elif 0.8 <= ovlap:\n",
    "        ovlap = 1\n",
    "    return ovlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVSPFeatures(r1, r2):\n",
    "    res = {'verb_ovlap_1_2' : getVerbSimilarityPortion(r1, r2), 'verb_ovlap_2_1' : getVerbSimilarityPortion(r2, r1)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRootLemma(r):\n",
    "    doc = nlp(r)\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'ROOT':\n",
    "            return t.lemma_\n",
    "    return 'nothing'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModalityType(r):\n",
    "    doc = nlp(r)\n",
    "    mvs = []\n",
    "    root_lemma = 'nothing'\n",
    "    for t in doc:\n",
    "        #print(t.lemma_ + t.tag_ + t.dep_)\n",
    "        if t.lemma_ == 'be':\n",
    "            if t.dep_ == 'ROOT':\n",
    "                return 'fact_be'\n",
    "        elif t.lemma_ == 'have':\n",
    "            if t.dep_ == 'ROOT':\n",
    "                if doc[t.i + 1].lemma_ == 'to':\n",
    "                    return 'obligatory'\n",
    "                else:\n",
    "                    return 'fact_hv'\n",
    "        elif t.lemma_ == 'need':\n",
    "            if t.dep_ == 'ROOT':\n",
    "                return 'fact_need'\n",
    "        elif t.tag_.startswith('MD'):\n",
    "            if t.head.dep_ == 'ROOT':\n",
    "                if t.lemma_ == 'must' or t.lemma_ == 'shall':\n",
    "                    return 'obligatory'\n",
    "                elif t.lemma_ == 'can' or t.lemma_ == 'could':\n",
    "                    return 'ability'\n",
    "                elif t.lemma_ == 'may':\n",
    "                    return 'permission'\n",
    "                elif t.lemma_ == 'should' or t.lemma_ == 'ought':\n",
    "                    return 'advice'\n",
    "                elif t.lemma_ == 'will':\n",
    "                    return 'futurative'\n",
    "    return 'unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModalityFeatures(r1, r2):\n",
    "    res = {'M_1': getModalityType(r1), 'root_1': getRootLemma(r1), 'M_2': getModalityType(r2), 'root_2': getRootLemma(r2)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubObjFeatures3(s1, s2):\n",
    "    doc1 = nlp(s1)\n",
    "    doc2 = nlp(s2)\n",
    "    res = {'subjsubj':[],'subjobj':[],'objsubj':[],'objobj':[]}\n",
    "    state = 'none'\n",
    "    for t1 in doc1:\n",
    "        if getOrigDep(t1).endswith('subj'):\n",
    "            state = 'subj'\n",
    "        elif getOrigDep(t1).endswith('obj'):\n",
    "            state = 'obj'\n",
    "        else:\n",
    "            continue\n",
    "        state2 = 'none'\n",
    "        for t2 in doc2:\n",
    "            if getOrigDep(t2).endswith('subj'):\n",
    "                state2 = 'subj'\n",
    "            elif getOrigDep(t2).endswith('obj'):\n",
    "                state2 = 'obj'\n",
    "            else:\n",
    "                continue\n",
    "          \n",
    "            key = state+state2\n",
    "            res[key].append(t1.lemma_.lower()+'.'+t2.lemma_)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubObjFeatures4(s1, s2):\n",
    "    doc1 = nlp(s1)\n",
    "    doc2 = nlp(s2)\n",
    "    res = {'first_subjs':[],'first_objs':[],'second_subjs':[],'second_objs':[]}\n",
    "    \n",
    "    for t1 in doc1:\n",
    "        if getOrigDep(t1).endswith('subj'):\n",
    "            res['first_subjs'].append(t1.lemma_.lower())\n",
    "        elif getOrigDep(t1).endswith('obj'):\n",
    "            res['first_objs'].append(t1.lemma_.lower())\n",
    "        else:\n",
    "            continue\n",
    "    for t2 in doc2:\n",
    "        if getOrigDep(t2).endswith('subj'):\n",
    "            res['second_subjs'].append(t2.lemma_.lower())\n",
    "        elif getOrigDep(t2).endswith('obj'):\n",
    "            res['second_objs'].append(t2.lemma_.lower())\n",
    "        else:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubObjFeatures5(s1, s2):\n",
    "    doc1 = nlp(s1)\n",
    "    doc2 = nlp(s2)\n",
    "    res = {'subj11':'NONE','subj12':'NONE','obj11':'NONE','obj12':'NONE', 'subj21': 'NONE','subj22':'NONE','obj21':'NONE','obj22':'NONE'}\n",
    "    \n",
    "    limit = 2\n",
    "    count_subj = 0\n",
    "    count_obj = 0\n",
    "    for t1 in doc1:\n",
    "        if count_subj < limit and getOrigDep(t1).endswith('subj'):\n",
    "            count_subj = count_subj + 1\n",
    "            res['subj1' + str(count_subj)] = t1.lemma_.lower()\n",
    "        elif count_obj < limit and getOrigDep(t1).endswith('obj'):\n",
    "            count_obj = count_obj + 1\n",
    "            res['obj1' + str(count_obj)] = t1.lemma_.lower()\n",
    "        else:\n",
    "            continue\n",
    "    count_subj = 0\n",
    "    count_obj = 0\n",
    "    for t2 in doc2:\n",
    "        if count_subj < limit and getOrigDep(t2).endswith('subj'):\n",
    "            count_subj = count_subj + 1\n",
    "            res['subj2' + str(count_subj)] = t2.lemma_.lower()\n",
    "        elif count_obj < limit and getOrigDep(t2).endswith('obj'):\n",
    "            count_obj = count_obj + 1\n",
    "            res['obj2' + str(count_obj)] = t2.lemma_.lower()\n",
    "        else:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDescribers(token):\n",
    "    res = []\n",
    "    tokens = []\n",
    "    for t in token.children:\n",
    "        if not t.dep_.endswith('subj') and not t.dep_.endswith('obj') and not t.dep_.endswith('aux') and not t.is_punct and not t.pos_.endswith('CONJ'):\n",
    "            tokens.append(t)\n",
    "    while tokens != []:\n",
    "        current = tokens.pop()\n",
    "        res.append(current)\n",
    "        for t in current.children:\n",
    "            if not t.dep_.endswith('subj') and not t.dep_.endswith('obj') and not t.dep_.endswith('aux') and not t.is_punct and not t.pos_.endswith('CONJ'):\n",
    "                tokens.append(t)\n",
    "    for t in res:\n",
    "        if t.pos_ == 'ADP' or t.pos_ == 'DET':\n",
    "            res.remove(t)    \n",
    "    return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatureFeatures8_Single(doc, num):\n",
    "    res = {'subj'+str(num)+'1': 'NONE','subj'+str(num)+'2':'NONE','obj'+str(num)+'1':'NONE','obj'+str(num)+'2':'NONE', 'root'+str(num): 'NONE', 'subj_des'+str(num): 'NONE', 'obj_des'+str(num): 'NONE', 'root_des'+str(num): 'NONE'}\n",
    "    limit = 2\n",
    "    count_subj = 0\n",
    "    count_obj = 0\n",
    "    subj_des = []\n",
    "    obj_des = []\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'ROOT':\n",
    "            res['root'+str(num)] = t.lemma_.lower()\n",
    "            des = getDescribers(t)\n",
    "            if len(des) > 0:\n",
    "                res['root_des'+str(num)] = des[0].lemma_.lower()\n",
    "        elif count_subj < limit and getOrigDep(t).endswith('subj'):\n",
    "            count_subj = count_subj + 1\n",
    "            res['subj'+ str(num) + str(count_subj)] = t.lemma_.lower()\n",
    "            subj_des = subj_des + getDescribers(t)\n",
    "        elif count_obj < limit and getOrigDep(t).endswith('obj'):\n",
    "            count_obj = count_obj + 1\n",
    "            res['obj'+ str(num) + str(count_obj)] = t.lemma_.lower()\n",
    "            obj_des = obj_des + getDescribers(t)\n",
    "        else:\n",
    "            continue\n",
    "    if len(subj_des) > 0:\n",
    "        res['subj_des'+ str(num)] = subj_des[0].lemma_.lower()\n",
    "    if len(obj_des) > 0:\n",
    "        res['obj_des'+ str(num)] = obj_des[0].lemma_.lower()\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatureFeatures5_Single(doc, num):\n",
    "    res = {'subj'+str(num)+'1': 'NONE','subj'+str(num)+'2':'NONE','obj'+str(num)+'1':'NONE','obj'+str(num)+'2':'NONE', 'root'+str(num): 'NONE'}\n",
    "    limit = 2\n",
    "    count_subj = 0\n",
    "    count_obj = 0\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'ROOT':\n",
    "            res['root'+str(num)] = t.lemma_.lower()\n",
    "        elif count_subj < limit and getOrigDep(t).endswith('subj'):\n",
    "            count_subj = count_subj + 1\n",
    "            res['subj'+ str(num) + str(count_subj)] = t.lemma_.lower()\n",
    "        elif count_obj < limit and getOrigDep(t).endswith('obj'):\n",
    "            count_obj = count_obj + 1\n",
    "            res['obj'+ str(num) + str(count_obj)] = t.lemma_.lower()\n",
    "        else:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatureFeatures16_Pair_Raw(r1, r2):\n",
    "    doc1 = nlp(r1)\n",
    "    doc2 = nlp(r2)\n",
    "    first = getMatureFeatures8_Single(doc1, 1)\n",
    "    first.update(getMatureFeatures8_Single(doc2, 2))\n",
    "    return first\n",
    "\n",
    "def getMatureFeatures10_Pair_Raw(r1, r2):\n",
    "    doc1 = nlp(r1)\n",
    "    doc2 = nlp(r2)\n",
    "    first = getMatureFeatures5_Single(doc1, 1)\n",
    "    first.update(getMatureFeatures5_Single(doc2, 2))\n",
    "    return first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#r1 = 'Crude oil for April delivery traded at $37.80 a barrel, down 28 cents'\n",
    "#r2 = 'Researchers at the Harvard School of Public Health say that people who drink coffee may be doing a lot more than keeping themselves awake - this kind of consumption apparently also can help reduce the risk of diseases.'\n",
    "\n",
    "#getMatureFeatures10_Pair_Raw(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFBag(r1, r2):\n",
    "    fbag = getStcSubObjFeatures2(r1, r2)\n",
    "    fbag.update(getNSPFeatures(r1, r2))\n",
    "    fbag.update(getVSPFeatures(r1, r2))\n",
    "    fbag.update(getModalityFeatures(r1, r2))\n",
    "    return fbag\n",
    "\n",
    "def createFBagNoOVLAP(r1, r2):\n",
    "    fbag = getStcSubObjFeatures2(r1, r2)\n",
    "    fbag.update(getModalityFeatures(r1, r2))\n",
    "    return fbag\n",
    "\n",
    "def createFBagNoSUBJOBJ(r1, r2):\n",
    "    fbag = getNSPFeatures(r1, r2)\n",
    "    fbag.update(getVSPFeatures(r1, r2))\n",
    "    fbag.update(getModalityFeatures(r1, r2))\n",
    "    return fbag\n",
    "\n",
    "def createFBagNoModal(r1, r2):\n",
    "    fbag = getStcSubObjFeatures2(r1, r2)\n",
    "    fbag.update(getNSPFeatures(r1, r2))\n",
    "    fbag.update(getVSPFeatures(r1, r2))\n",
    "    return fbag\n",
    "\n",
    "def createFBagRootSUBJOBJ(r1, r2):\n",
    "    fbag = getModalityFeatures(r1, r2)\n",
    "    fbag.update(getSubObjFeatures5(r1, r2))\n",
    "    return fbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'M_1': 'obligatory', 'root_1': 'be', 'M_2': 'obligatory', 'root_2': 'be', 'first_subjs': ['mode'], 'first_objs': [], 'second_subjs': ['user'], 'second_objs': ['mode']}\n"
     ]
    }
   ],
   "source": [
    "#r1 = 'Mode must be either automatic or manual.'\n",
    "#r2 = 'Users must be able to set the mode.'\n",
    "#features = []\n",
    "#tmp = createFBagRootSUBJOBJ(r1, r2)\n",
    "#print(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
