{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model='en_pytt_bertbaseuncased_lg'\n",
    "model = 'en_core_web_lg'\n",
    "nlp = spacy.load(model)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSynAnt(word):\n",
    "    synonyms = [] \n",
    "    antonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "            if l.antonyms(): \n",
    "                antonyms.append(l.antonyms()[0].name()) \n",
    "    return synonyms, antonyms\n",
    "\n",
    "def getWUPSimilarity(doc1, doc2):\n",
    "    if doc1.lemma_.lower() == doc2.lemma_.lower():\n",
    "        return 1\n",
    "    \n",
    "    w1 = doc1.text\n",
    "    w2 = doc2.text\n",
    "    synonyms, _ = getSynAnt(w1)\n",
    "    if w2 in synonyms:\n",
    "        return 0.9\n",
    "    synonyms, _ = getSynAnt(w2)\n",
    "    if w1 in synonyms:\n",
    "        return 0.9\n",
    "\n",
    "    #NOUN\n",
    "    synw1s = wordnet.synsets(w1, wordnet.NOUN)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "    #VERB\n",
    "    synw1s = wordnet.synsets(w1, wordnet.VERB)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "    #ADJ\n",
    "    synw1s = wordnet.synsets(w1, wordnet.ADJ)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "    #ADV\n",
    "    synw1s = wordnet.synsets(w1, wordnet.ADV)\n",
    "    if len(synw1s) > 0:\n",
    "        synw2s = wordnet.synsets(w2, wordnet.NOUN)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.VERB)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADJ)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        synw2s = wordnet.synsets(w2, wordnet.ADV)\n",
    "        if len(synw2s) > 0:\n",
    "            return synw1s[0].wup_similarity(synw2s[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "def getAntonymity(doc1, doc2):\n",
    "    w1 = doc1.text\n",
    "    w2 = doc2.text\n",
    "    antonyms = [] \n",
    "    for syn in wordnet.synsets(w1): \n",
    "        for l in syn.lemmas(): \n",
    "            if l.antonyms():\n",
    "                antonyms.append(l.antonyms()[0].name()) \n",
    "    if len(antonyms) < 1:\n",
    "        return 0\n",
    "    if w2 in antonyms:\n",
    "        return 1\n",
    "    avg = 0\n",
    "    for a in antonyms:\n",
    "        tmp = getWUPSimilarity(doc2, nlp(a)[0])\n",
    "        if tmp == None:\n",
    "            tmp = 0\n",
    "        avg = avg + tmp\n",
    "    if len(antonyms) > 0:\n",
    "        #avg = avg / len(antonyms)\n",
    "        avg = avg\n",
    "    else:\n",
    "        return 0\n",
    "    return avg\n",
    "\n",
    "def getOrigDep(word):\n",
    "    if (word.dep_ != 'conj'):\n",
    "        return word.dep_\n",
    "    return getOrigDep(word.head)\n",
    "\n",
    "\n",
    "def isStopWord(w):\n",
    "    if w.pos_ == 'DET':\n",
    "        return True\n",
    "    if w in set(nltk.corpus.stopwords.words('english')):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def getMax(a_list):\n",
    "    if len(a_list) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return max(a_list, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item(object):\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "        self.synonyms, self.antonyms = getSynAnt(self.token.text)\n",
    "        self.describers = self.getDescribers(self.token)\n",
    "    \n",
    "    def getDescribers(self, token):\n",
    "        res = []\n",
    "        tokens = []\n",
    "        for t in token.children:\n",
    "            if not t.dep_.endswith('subj') and not t.dep_.endswith('obj') and not t.dep_.endswith('aux') and not t.is_punct and not t.pos_.endswith('CONJ'):\n",
    "                tokens.append(t)\n",
    "        while tokens != []:\n",
    "            current = tokens.pop()\n",
    "            res.append(current)\n",
    "            for t in current.children:\n",
    "                if not t.dep_.endswith('subj') and not t.dep_.endswith('obj') and not t.dep_.endswith('aux') and not t.is_punct and not t.pos_.endswith('CONJ'):\n",
    "                    tokens.append(t)\n",
    "        for t in res:\n",
    "            if t.pos_ == 'ADP' or t.pos_ == 'DET':\n",
    "                res.remove(t)    \n",
    "        return res       \n",
    "        \n",
    "        \n",
    "        \n",
    "class Specification(object):\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.doc = nlp(text)\n",
    "        self.objs = []\n",
    "        self.subjs = []\n",
    "        self.verbs = []\n",
    "        self.loadItems()\n",
    "        \n",
    "    def loadItems(self):\n",
    "        for token in self.doc:\n",
    "            if getOrigDep(token).endswith('subj'):\n",
    "                self.subjs.append(Item(token))\n",
    "            elif getOrigDep(token).endswith('obj'):\n",
    "                self.objs.append(Item(token))\n",
    "            elif token.pos_ == 'VERB':\n",
    "                self.verbs.append(Item(token))\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    def getAllItems(self):\n",
    "        return self.objs + self.subjs + self.verbs\n",
    "    \n",
    "    def getItem(self, word_text):\n",
    "        for item in self.getAllItems():\n",
    "            if item.text == word_text:\n",
    "                return item\n",
    "        return None\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(object):\n",
    "   \n",
    "    \n",
    "    def getOneValueSim(self, token1, token2):\n",
    "        sim = getWUPSimilarity(token1, token2)\n",
    "        if sim == None:\n",
    "            sim = 0\n",
    "        ant = getAntonymity(token1, token2)\n",
    "        if ant == None:\n",
    "            ant = 0\n",
    "        ant = ant * -1\n",
    "        res = ant + sim\n",
    "        return res\n",
    "        \n",
    "        \n",
    "    def getRelationship(self, item1, item2):\n",
    "        non_zeros = []\n",
    "        \n",
    "        item1item2_sim = self.getOneValueSim(item1.token, item2.token)\n",
    "        if not item1item2_sim == 0:\n",
    "            non_zeros.append(item1item2_sim)\n",
    "        \n",
    "        des1item2_sim_list = []\n",
    "        for d in item1.describers:\n",
    "            des1item2_sim_list.append(self.getOneValueSim(d, item2.token))\n",
    "        des1item2_sim = getMax(des1item2_sim_list)\n",
    "        if not des1item2_sim == 0:\n",
    "            non_zeros.append(des1item2_sim)\n",
    "        \n",
    "        item1des2_sim_list = []\n",
    "        for d in item2.describers:\n",
    "            item1des2_sim_list.append(self.getOneValueSim(item1.token, d))\n",
    "        item1des2_sim = getMax(item1des2_sim_list)\n",
    "        if not item1des2_sim == 0:\n",
    "            non_zeros.append(item1des2_sim)\n",
    "        \n",
    "        des1des2_sim_list = []\n",
    "        for d1 in item1.describers:\n",
    "            for d2 in item2.describers: \n",
    "                des1des2_sim_list.append(self.getOneValueSim(d1, d2))\n",
    "        des1des2_sim = getMax(des1des2_sim_list)\n",
    "        if not des1des2_sim == 0:\n",
    "            non_zeros.append(des1des2_sim)\n",
    "            \n",
    "        sign = 1\n",
    "        for val in non_zeros:\n",
    "            sign = sign * val\n",
    "        sign = np.sign(sign)\n",
    "        res = pow(2, item1item2_sim+1)\n",
    "        res = res * pow(2, item1des2_sim+1)\n",
    "        res = res * pow(2, des1item2_sim+1)\n",
    "        res = res * pow(2, des1des2_sim+1)\n",
    "        res = pow(res, 0.25) * sign\n",
    "        return res\n",
    "    \n",
    "    def updateResDict(self, res, ant_res, key, val):\n",
    "        if val < 0:\n",
    "            if key in ant_res.keys():\n",
    "                ant_res[key].append(val)\n",
    "            else:\n",
    "                ant_res[key] = [val]\n",
    "        else:\n",
    "            if key in res.keys():\n",
    "                res[key].append(val)\n",
    "            else:\n",
    "                res[key] = [val]\n",
    "        return res, ant_res\n",
    "\n",
    "    #returns synonymity and antonymity of subjects and objects\n",
    "    def getSubObjFeaturesFirst(self, spec1, spec2):\n",
    "        res = {}\n",
    "        ant_res = {}\n",
    "        for t1 in spec1.subjs:\n",
    "            for t2 in spec2.subjs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'subjsubj', self.getRelationship(t1, t2))\n",
    "            for t2 in spec2.verbs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'subjverb', self.getRelationship(t1, t2))\n",
    "        for t1 in spec1.subjs:\n",
    "            for t2 in spec2.objs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'subjobj', self.getRelationship(t1, t2))\n",
    "        for t1 in spec1.objs:\n",
    "            for t2 in spec2.subjs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'objsubj', self.getRelationship(t1, t2))\n",
    "            for t2 in spec2.verbs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'objverb', self.getRelationship(t1, t2))\n",
    "        for t1 in spec1.objs:\n",
    "            for t2 in spec2.objs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'objobj', self.getRelationship(t1, t2))\n",
    "        for t1 in spec1.verbs:\n",
    "            for t2 in spec2.objs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'verbobj', self.getRelationship(t1, t2))\n",
    "            for t2 in spec2.subjs:\n",
    "                res, ant_res = self.updateResDict(res, ant_res, 'verbsubj', self.getRelationship(t1, t2))\n",
    "        return res, ant_res\n",
    "    \n",
    "    def getSubObjFeaturesFinal(self, spec1, spec2):\n",
    "        states = ['subj', 'obj', 'verb']\n",
    "        res, ant_res = self.getSubObjFeaturesFirst(spec1, spec2)\n",
    "        final_res = {}\n",
    "        for s1 in states:\n",
    "            for s2 in states:\n",
    "                key = s1 + s2\n",
    "                if key in res.keys():\n",
    "                    final_res[key] = np.mean(res[key])\n",
    "                else:\n",
    "                    final_res[key] = 0\n",
    "                if key in ant_res.keys():\n",
    "                    final_res['ant_'+key] = np.mean(ant_res[key])\n",
    "                else:\n",
    "                    final_res['ant_'+key] = 0\n",
    "        return final_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjsubj 3.08\n",
      "ant_subjsubj 0\n",
      "subjobj 2.08\n",
      "ant_subjobj 0\n",
      "subjverb 2.16\n",
      "ant_subjverb 0\n",
      "objsubj 2.24\n",
      "ant_objsubj 0\n",
      "objobj 2.32\n",
      "ant_objobj 0\n",
      "objverb 2.1\n",
      "ant_objverb 0\n",
      "verbsubj 1.13\n",
      "ant_verbsubj 0\n",
      "verbobj 2.0\n",
      "ant_verbobj -1.73\n",
      "verbverb 0\n",
      "ant_verbverb 0\n"
     ]
    }
   ],
   "source": [
    "r1 = 'Crude oil for April delivery traded at $37.80 a barrel, decrease 28 cents.'\n",
    "r2 = 'Crude oil prices rose to $37.80 per barrel.'\n",
    "\n",
    "spec1 = Specification(r1)\n",
    "spec2 = Specification(r2)\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "x = fe.getSubObjFeaturesFinal(spec1, spec2)\n",
    "for key in x.keys():\n",
    "    print(key, round(x[key],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
