{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ga75xoh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, make_scorer\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "import Feature_Extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.parse('data/RTE1_dev1_3ways.xml').getroot()\n",
    "r1 = []\n",
    "r2 = []\n",
    "y = []\n",
    "for el in list(root):\n",
    "    label = el.get('entailment')\n",
    "    if label == 'YES':\n",
    "        y.append(-1)\n",
    "    elif label == 'NO':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        continue\n",
    "    r1.append(list(el)[0].text)\n",
    "    r2.append(list(el)[1].text)\n",
    "    \n",
    "root = ET.parse('data/RTE1_dev2_3ways.xml').getroot()\n",
    "for el in list(root):\n",
    "    label = el.get('entailment')\n",
    "    if label == 'YES':\n",
    "        y.append(-1)\n",
    "    elif label == 'NO':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        continue\n",
    "    r1.append(list(el)[0].text)\n",
    "    r2.append(list(el)[1].text)\n",
    "    \n",
    "r1t = []\n",
    "r2t = []\n",
    "yt = []\n",
    "root = ET.parse('data/RTE1_test_3ways.xml').getroot()\n",
    "for el in list(root):\n",
    "    label = el.get('entailment')\n",
    "    if label == 'YES':\n",
    "        yt.append(-1)\n",
    "    elif label == 'NO':\n",
    "        yt.append(1)\n",
    "    else:\n",
    "        continue\n",
    "    r1t.append(list(el)[0].text)\n",
    "    r2t.append(list(el)[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = r1 + r1t[:365]\n",
    "r2 = r2 + r2t[:365]\n",
    "y = y + yt[:365]\n",
    "r1t = r1t[-184:]\n",
    "r2t = r2t[-184:]\n",
    "yt = yt[-184:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(len(y)):\n",
    "    x.append(fe.createFBag(r1[i], r2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for i in range(len(yt)):\n",
    "    x_test.append(fe.createFBag(r1t[i], r2t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()\n",
    "xx = vec.fit_transform(x).toarray()\n",
    "xx_test = vec.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.82      0.77       125\n",
      "           1       0.48      0.34      0.40        59\n",
      "\n",
      "    accuracy                           0.67       184\n",
      "   macro avg       0.60      0.58      0.58       184\n",
      "weighted avg       0.65      0.67      0.65       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_clf =  LogisticRegression(C=4.281332398719396, class_weight='balanced', penalty= 'l1', solver= 'liblinear')\n",
    "LR_clf.fit(xx, y)\n",
    "y_pred = LR_clf.predict(xx_test)\n",
    "print(classification_report(yt, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 599)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 128)         76672     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_10  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 102,497\n",
      "Trainable params: 102,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(599, 128))\n",
    "#model.add(keras.layers.Dense(units=20, activation='relu', input_shape=xx.shape))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - ETA: 4s - loss: 0.6790 - acc: 0.0000e+0 - ETA: 1s - loss: 0.6406 - acc: 0.0000e+0 - ETA: 0s - loss: 0.6086 - acc: 0.0000e+0 - ETA: 0s - loss: 0.5739 - acc: 0.0000e+0 - ETA: 0s - loss: 0.5267 - acc: 0.0000e+0 - ETA: 0s - loss: 0.4877 - acc: 0.0000e+0 - ETA: 0s - loss: 0.4369 - acc: 0.0000e+0 - ETA: 0s - loss: 0.3857 - acc: 0.0000e+0 - 1s 798us/sample - loss: 0.3528 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xx,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - ETA: 0s - loss: -0.4490 - acc: 0.0000e+ - 0s 661us/sample - loss: -0.1411 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.1410935433662456, 0.0]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(xx_test, yt)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
